{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a mostly non-technical demo notebook for a CNN model that predicts March Madness games\n",
    "##### Below are imports, more than are in use, just extra tools in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import en_core_web_sm\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from IPython import display\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_columns = 10\n",
    "pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'monospace'\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import os, eli5, shap\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from pdpbox import pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes that will be used for performance comparison later\n",
    "pastModels=[[2017,1,.43857],[2017,2,.44981],[2017,3,.45373],[2017,4,.46100],[2017,5,.46107],[2018,1,.53194],[2018,2,.53693],[2018,3,.54013],[2018,4,.54967],[2018,5,.54987],[2019,1,.41477],[2019,2,.42012],[2019,3,.42698],[2019,4,.42788],[2019,5,.43148]]\n",
    "cols=['Year','Rank','LogLoss']\n",
    "pastScores=pd.DataFrame(pastModels, columns=cols)\n",
    "pastMadness=[[2017,65.7,82,78,68],[2018,57,81,108,95],[2019,74,124,131,99]]\n",
    "cols=['Year','avg_score','higherSeed_score','myScore','percentile_myScore']\n",
    "pastMadness=pd.DataFrame(pastMadness, columns=cols)\n",
    "inputs=39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data here and slicing it in different ways for training and testing model\n",
    "##### We will only be showing testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_data=pd.read_csv(\"../Data/TourneyData/tourney_game_master_scaled_all.csv\")\n",
    "removeList=['Ats_pct','Aie','Afour','Aelo','Bts_pct','Bie','Bfour','Belo','ts_pct_diff','ie_diff','four_diff','elo_diff']\n",
    "if any(elem in tourney_data.columns  for elem in removeList):\n",
    "    tourney_data=tourney_data.drop(removeList,axis=1)\n",
    "tourney_data.dropna(subset=['AdjEM_diff'], how='all',inplace=True)\n",
    "train_data=tourney_data[(tourney_data['Season']<2017)&(tourney_data['Season']>2006)].reset_index(drop=True)\n",
    "test_data=tourney_data[tourney_data['Season']>2016].reset_index(drop=True)\n",
    "\n",
    "train_output_data=pd.DataFrame()\n",
    "test_output_data=pd.DataFrame()\n",
    "col_names = ['Season','tourn_round','point_diff','ATeamID','ATeam','ASeed','Aregion','BTeamID','BTeam','BSeed','Bregion']\n",
    "train_other_data=train_data.iloc[:,inputs:inputs+11]\n",
    "train_output_data['AWon']=train_data.AWon\n",
    "train_output_data['Season']=train_data.Season\n",
    "test_other_data=test_data.iloc[:,inputs:inputs+11]\n",
    "test_output_data['AWon']=test_data.AWon\n",
    "test_output_data['Season']=test_data.Season\n",
    "train_data=train_data.iloc[:,:inputs]\n",
    "test_data=test_data.iloc[:,:inputs]\n",
    "\n",
    "\n",
    "test_full_data=test_input_data\n",
    "test_full_data[col_names] = test_other_data \n",
    "test_full_data['AWon']=test_output_data.AWon\n",
    "test_output_data['Season']=test_other_data['Season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we have a sample of some rows that will be used as inputs to predict the outcome of some March Madness games\n",
    "##### Does not show all inputs, these inputs are an array of end of season stats for each team and then a comparison differential of said stats\n",
    "###### Below we also have they testing output data which has the actual outcomes we will be trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asos</th>\n",
       "      <th>Amov</th>\n",
       "      <th>APOM</th>\n",
       "      <th>ASAG</th>\n",
       "      <th>AMOR</th>\n",
       "      <th>...</th>\n",
       "      <th>BTeamID</th>\n",
       "      <th>BTeam</th>\n",
       "      <th>BSeed</th>\n",
       "      <th>Bregion</th>\n",
       "      <th>AWon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.205992</td>\n",
       "      <td>-1.099475</td>\n",
       "      <td>-2.671724</td>\n",
       "      <td>-2.741144</td>\n",
       "      <td>-2.244242</td>\n",
       "      <td>...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498742</td>\n",
       "      <td>0.379470</td>\n",
       "      <td>0.411734</td>\n",
       "      <td>0.441606</td>\n",
       "      <td>0.399211</td>\n",
       "      <td>...</td>\n",
       "      <td>saint-marys</td>\n",
       "      <td>7.0</td>\n",
       "      <td>X</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.524222</td>\n",
       "      <td>-1.391061</td>\n",
       "      <td>-0.253325</td>\n",
       "      <td>-0.182857</td>\n",
       "      <td>0.144656</td>\n",
       "      <td>...</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056525</td>\n",
       "      <td>0.044417</td>\n",
       "      <td>-0.958692</td>\n",
       "      <td>-1.149769</td>\n",
       "      <td>-2.655446</td>\n",
       "      <td>...</td>\n",
       "      <td>baylor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>W</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.777871</td>\n",
       "      <td>-0.841366</td>\n",
       "      <td>-0.414552</td>\n",
       "      <td>-0.303721</td>\n",
       "      <td>-0.207804</td>\n",
       "      <td>...</td>\n",
       "      <td>baylor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>W</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Asos      Amov      APOM      ASAG      AMOR  ...       BTeamID  BTeam  \\\n",
       "0 -1.205992 -1.099475 -2.671724 -2.741144 -2.244242  ...       arizona    2.0   \n",
       "1  0.498742  0.379470  0.411734  0.441606  0.399211  ...   saint-marys    7.0   \n",
       "2 -1.524222 -1.391061 -0.253325 -0.182857  0.144656  ...      arkansas    8.0   \n",
       "3  0.056525  0.044417 -0.958692 -1.149769 -2.655446  ...        baylor    3.0   \n",
       "4 -0.777871 -0.841366 -0.414552 -0.303721 -0.207804  ...        baylor    3.0   \n",
       "\n",
       "   BSeed  Bregion  AWon  \n",
       "0      X      -18     0  \n",
       "1      X        9     1  \n",
       "2      Z       -6     0  \n",
       "3      W      -18     0  \n",
       "4      W       -4     0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show sample of DataFrame\n",
    "test_input_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWon</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AWon  Season\n",
       "0     0    2017\n",
       "1     1    2017\n",
       "2     0    2017\n",
       "3     0    2017\n",
       "4     0    2017"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model Framework and Weights\n",
    "##### This loads a file that has the saved framework and tuned model, it then loads the weights which will be used for predicting games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from disk\n"
     ]
    }
   ],
   "source": [
    "#Load Model and weights\n",
    "json_file = open('../winModeling/tournament_win_model_prod.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "optimizer = keras.optimizers.Adagrad(lr=.01,epsilon=0,decay=0)\n",
    "model.compile(optimizer= optimizer ,loss='binary_crossentropy',metrics=['acc'])\n",
    "model.load_weights('../winModeling/tournament_win_weights_prod.h5')\n",
    "\n",
    "print(\"Loaded model weights from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How we show performance?\n",
    "##### The primary basis for measuring a model performance is measuring 'Log Loss' or basically a measure of accuracy that factors in confidence\n",
    "##### Below we will show: Log Loss for random choice of winner/confidence, The Log Loss for the Top 5 models as part of the Kaggle NCAA competition for the 3 years we are testing\n",
    "##### Link to Kaggle Leaderboard for 2019: https://www.kaggle.com/c/mens-machine-learning-competition-2019/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(predictions, realizations):\n",
    "    predictions_use = predictions.clip(0)\n",
    "    realizations_use = realizations.clip(0)\n",
    "    LogLoss = -np.mean( (realizations_use * np.log(predictions_use)) + \n",
    "                        (1 - realizations_use) * np.log(1 - predictions_use) )\n",
    "    return LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599452"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For reference this is the LogLoss of a model that predicts 50/50 shot of either team winning each time\n",
    "#rather than favoring one team or another\n",
    "\n",
    "bench_5050 = np.repeat(0.5, len(test_output_data))\n",
    "LogLoss(bench_5050, test_output_data.AWon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.44981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0.45373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>0.46107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.53693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>0.54987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.42012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.42698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.42788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>0.43148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Rank  LogLoss\n",
       "0   2017     1  0.43857\n",
       "1   2017     2  0.44981\n",
       "2   2017     3  0.45373\n",
       "3   2017     4  0.46100\n",
       "4   2017     5  0.46107\n",
       "5   2018     1  0.53194\n",
       "6   2018     2  0.53693\n",
       "7   2018     3  0.54013\n",
       "8   2018     4  0.54967\n",
       "9   2018     5  0.54987\n",
       "10  2019     1  0.41477\n",
       "11  2019     2  0.42012\n",
       "12  2019     3  0.42698\n",
       "13  2019     4  0.42788\n",
       "14  2019     5  0.43148"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log Loss for past Kaggle competition winners\n",
    "pastScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does my model stack up?\n",
    "##### Here is a readout of accuracy followed by Log Loss for the 3 years of Kaggle competition shown above\n",
    "##### We then show a sample of outputs for the models outputted prediction/confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 67.16%\n",
      "LL_Test  2017 :  AWon    0.584546\n",
      "dtype: float64\n",
      "acc: 70.15%\n",
      "LL_Test  2018 :  AWon    0.584034\n",
      "dtype: float64\n",
      "acc: 67.16%\n",
      "LL_Test  2019 :  AWon    0.524332\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asos</th>\n",
       "      <th>Amov</th>\n",
       "      <th>APOM</th>\n",
       "      <th>ASAG</th>\n",
       "      <th>AMOR</th>\n",
       "      <th>Awins_top25</th>\n",
       "      <th>Awins_top5</th>\n",
       "      <th>Awin_pct</th>\n",
       "      <th>AAdjDE</th>\n",
       "      <th>AAdjOE</th>\n",
       "      <th>AAdjEM</th>\n",
       "      <th>AAdjsos</th>\n",
       "      <th>ALuck</th>\n",
       "      <th>Bsos</th>\n",
       "      <th>Bmov</th>\n",
       "      <th>BPOM</th>\n",
       "      <th>BSAG</th>\n",
       "      <th>BMOR</th>\n",
       "      <th>Bwins_top25</th>\n",
       "      <th>Bwins_top5</th>\n",
       "      <th>Bwin_pct</th>\n",
       "      <th>BAdjDE</th>\n",
       "      <th>BAdjOE</th>\n",
       "      <th>BAdjEM</th>\n",
       "      <th>BAdjsos</th>\n",
       "      <th>BLuck</th>\n",
       "      <th>sos_diff</th>\n",
       "      <th>mov_diff</th>\n",
       "      <th>POM_diff</th>\n",
       "      <th>SAG_diff</th>\n",
       "      <th>MOR_diff</th>\n",
       "      <th>wins_top25_diff</th>\n",
       "      <th>wins_top5_diff</th>\n",
       "      <th>win_pct_diff</th>\n",
       "      <th>AdjDE_diff</th>\n",
       "      <th>AdjOE_diff</th>\n",
       "      <th>AdjEM_diff</th>\n",
       "      <th>Adjsos_diff</th>\n",
       "      <th>Luck_diff</th>\n",
       "      <th>y_pred_confidence</th>\n",
       "      <th>y_pred_test</th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-1.664805</td>\n",
       "      <td>-1.761074</td>\n",
       "      <td>-2.893411</td>\n",
       "      <td>-3.003016</td>\n",
       "      <td>-2.224661</td>\n",
       "      <td>-1.098913</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>-0.752348</td>\n",
       "      <td>-2.117587</td>\n",
       "      <td>-1.685875</td>\n",
       "      <td>-2.360871</td>\n",
       "      <td>-1.326659</td>\n",
       "      <td>3.098915</td>\n",
       "      <td>1.462180</td>\n",
       "      <td>1.129679</td>\n",
       "      <td>0.819705</td>\n",
       "      <td>0.785599</td>\n",
       "      <td>0.818690</td>\n",
       "      <td>1.051227</td>\n",
       "      <td>1.242486</td>\n",
       "      <td>1.876212</td>\n",
       "      <td>2.038038</td>\n",
       "      <td>0.622339</td>\n",
       "      <td>1.622996</td>\n",
       "      <td>-0.296524</td>\n",
       "      <td>-0.608768</td>\n",
       "      <td>-2.209353</td>\n",
       "      <td>-2.030496</td>\n",
       "      <td>-2.667672</td>\n",
       "      <td>-2.741074</td>\n",
       "      <td>-2.165312</td>\n",
       "      <td>-1.394692</td>\n",
       "      <td>-1.237425</td>\n",
       "      <td>-1.865825</td>\n",
       "      <td>-2.849282</td>\n",
       "      <td>-1.593388</td>\n",
       "      <td>-2.686226</td>\n",
       "      <td>-0.720204</td>\n",
       "      <td>-1.874851</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.768515</td>\n",
       "      <td>0.472194</td>\n",
       "      <td>0.401318</td>\n",
       "      <td>0.438373</td>\n",
       "      <td>0.158626</td>\n",
       "      <td>1.055815</td>\n",
       "      <td>0.340995</td>\n",
       "      <td>-0.099016</td>\n",
       "      <td>0.477517</td>\n",
       "      <td>0.262148</td>\n",
       "      <td>0.537661</td>\n",
       "      <td>-0.249725</td>\n",
       "      <td>0.284002</td>\n",
       "      <td>0.233007</td>\n",
       "      <td>0.645141</td>\n",
       "      <td>0.611270</td>\n",
       "      <td>0.667672</td>\n",
       "      <td>0.628164</td>\n",
       "      <td>1.242486</td>\n",
       "      <td>0.436840</td>\n",
       "      <td>0.438999</td>\n",
       "      <td>0.513686</td>\n",
       "      <td>0.600095</td>\n",
       "      <td>-0.394365</td>\n",
       "      <td>0.353885</td>\n",
       "      <td>0.240998</td>\n",
       "      <td>0.365533</td>\n",
       "      <td>-0.141132</td>\n",
       "      <td>-0.168181</td>\n",
       "      <td>-0.179063</td>\n",
       "      <td>-0.302183</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.067778</td>\n",
       "      <td>-0.374389</td>\n",
       "      <td>-0.027938</td>\n",
       "      <td>-0.235195</td>\n",
       "      <td>0.657889</td>\n",
       "      <td>-0.088636</td>\n",
       "      <td>0.676542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.211482</td>\n",
       "      <td>1.066883</td>\n",
       "      <td>0.653574</td>\n",
       "      <td>0.643046</td>\n",
       "      <td>0.692928</td>\n",
       "      <td>0.158626</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>0.584699</td>\n",
       "      <td>1.746456</td>\n",
       "      <td>-0.039163</td>\n",
       "      <td>0.989735</td>\n",
       "      <td>-0.384109</td>\n",
       "      <td>-0.301651</td>\n",
       "      <td>0.785278</td>\n",
       "      <td>1.055584</td>\n",
       "      <td>0.354200</td>\n",
       "      <td>0.320722</td>\n",
       "      <td>0.384515</td>\n",
       "      <td>-1.064086</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>1.575975</td>\n",
       "      <td>0.062119</td>\n",
       "      <td>0.359011</td>\n",
       "      <td>0.273838</td>\n",
       "      <td>0.719422</td>\n",
       "      <td>-0.700520</td>\n",
       "      <td>0.279968</td>\n",
       "      <td>-0.017501</td>\n",
       "      <td>0.203396</td>\n",
       "      <td>0.222089</td>\n",
       "      <td>0.207153</td>\n",
       "      <td>0.790326</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.703032</td>\n",
       "      <td>1.126951</td>\n",
       "      <td>-0.276348</td>\n",
       "      <td>0.473754</td>\n",
       "      <td>-0.781340</td>\n",
       "      <td>0.779998</td>\n",
       "      <td>0.714511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-1.042908</td>\n",
       "      <td>-1.017338</td>\n",
       "      <td>-0.434705</td>\n",
       "      <td>-0.263433</td>\n",
       "      <td>-0.305710</td>\n",
       "      <td>-0.260554</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>-0.652568</td>\n",
       "      <td>-0.789388</td>\n",
       "      <td>-0.552179</td>\n",
       "      <td>-0.828998</td>\n",
       "      <td>-0.809681</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>-1.344465</td>\n",
       "      <td>-1.409769</td>\n",
       "      <td>-0.596208</td>\n",
       "      <td>-0.357224</td>\n",
       "      <td>-0.521589</td>\n",
       "      <td>-1.064086</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>-1.126158</td>\n",
       "      <td>-1.160098</td>\n",
       "      <td>-0.544817</td>\n",
       "      <td>-1.049577</td>\n",
       "      <td>-0.906992</td>\n",
       "      <td>-0.039497</td>\n",
       "      <td>0.238932</td>\n",
       "      <td>0.305798</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>0.077544</td>\n",
       "      <td>0.165772</td>\n",
       "      <td>0.517198</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>0.335620</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.163935</td>\n",
       "      <td>0.076890</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.632692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.594948</td>\n",
       "      <td>-0.433107</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.119303</td>\n",
       "      <td>0.242562</td>\n",
       "      <td>0.158626</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>-1.071642</td>\n",
       "      <td>-1.053316</td>\n",
       "      <td>0.483624</td>\n",
       "      <td>-0.288870</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>-1.003087</td>\n",
       "      <td>1.711595</td>\n",
       "      <td>1.847849</td>\n",
       "      <td>0.683933</td>\n",
       "      <td>0.630640</td>\n",
       "      <td>0.629918</td>\n",
       "      <td>-0.641023</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>1.311060</td>\n",
       "      <td>-0.017563</td>\n",
       "      <td>1.192595</td>\n",
       "      <td>0.776362</td>\n",
       "      <td>1.374932</td>\n",
       "      <td>-0.286472</td>\n",
       "      <td>-1.643282</td>\n",
       "      <td>-1.625121</td>\n",
       "      <td>-0.428239</td>\n",
       "      <td>-0.384998</td>\n",
       "      <td>-0.289410</td>\n",
       "      <td>0.517198</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-1.691579</td>\n",
       "      <td>-0.693647</td>\n",
       "      <td>-0.495314</td>\n",
       "      <td>-0.723685</td>\n",
       "      <td>-0.968338</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.254391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-2.060314</td>\n",
       "      <td>-1.994766</td>\n",
       "      <td>-3.578624</td>\n",
       "      <td>-3.224600</td>\n",
       "      <td>-3.379948</td>\n",
       "      <td>-1.098913</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>-1.271201</td>\n",
       "      <td>-1.576473</td>\n",
       "      <td>-2.652265</td>\n",
       "      <td>-2.693156</td>\n",
       "      <td>-1.897097</td>\n",
       "      <td>3.410371</td>\n",
       "      <td>0.112233</td>\n",
       "      <td>0.080894</td>\n",
       "      <td>-2.109102</td>\n",
       "      <td>-2.642869</td>\n",
       "      <td>-3.126639</td>\n",
       "      <td>-1.064086</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>-0.165400</td>\n",
       "      <td>-1.311863</td>\n",
       "      <td>-1.753497</td>\n",
       "      <td>-1.937224</td>\n",
       "      <td>-0.232148</td>\n",
       "      <td>-2.657369</td>\n",
       "      <td>-1.515576</td>\n",
       "      <td>-1.440441</td>\n",
       "      <td>-0.988097</td>\n",
       "      <td>-0.341635</td>\n",
       "      <td>-0.096302</td>\n",
       "      <td>-0.029056</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.785592</td>\n",
       "      <td>-0.136134</td>\n",
       "      <td>-0.608667</td>\n",
       "      <td>-0.474139</td>\n",
       "      <td>-1.166365</td>\n",
       "      <td>-0.500353</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.744107</td>\n",
       "      <td>0.412869</td>\n",
       "      <td>0.673727</td>\n",
       "      <td>0.622902</td>\n",
       "      <td>0.614604</td>\n",
       "      <td>0.577805</td>\n",
       "      <td>1.055815</td>\n",
       "      <td>-0.652568</td>\n",
       "      <td>1.553631</td>\n",
       "      <td>0.110903</td>\n",
       "      <td>0.978132</td>\n",
       "      <td>-0.948180</td>\n",
       "      <td>-1.320760</td>\n",
       "      <td>0.574329</td>\n",
       "      <td>0.588910</td>\n",
       "      <td>0.664537</td>\n",
       "      <td>0.630640</td>\n",
       "      <td>0.573287</td>\n",
       "      <td>-0.641023</td>\n",
       "      <td>1.242486</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>1.062118</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.965138</td>\n",
       "      <td>-0.183720</td>\n",
       "      <td>0.803607</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>-0.136135</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>-0.023637</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.790326</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.463343</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>-0.274545</td>\n",
       "      <td>-0.006612</td>\n",
       "      <td>-0.534805</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.596478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.189723</td>\n",
       "      <td>0.237422</td>\n",
       "      <td>0.331121</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>-0.070736</td>\n",
       "      <td>-1.098913</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>0.402748</td>\n",
       "      <td>-1.399115</td>\n",
       "      <td>1.195391</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>1.349864</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>1.793258</td>\n",
       "      <td>1.834774</td>\n",
       "      <td>0.761517</td>\n",
       "      <td>0.688749</td>\n",
       "      <td>0.686550</td>\n",
       "      <td>0.205102</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>1.311060</td>\n",
       "      <td>1.696000</td>\n",
       "      <td>0.038761</td>\n",
       "      <td>1.034478</td>\n",
       "      <td>-0.112957</td>\n",
       "      <td>-0.227225</td>\n",
       "      <td>-1.155398</td>\n",
       "      <td>-1.151047</td>\n",
       "      <td>-0.327751</td>\n",
       "      <td>-0.500634</td>\n",
       "      <td>-0.551484</td>\n",
       "      <td>-0.848438</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.644285</td>\n",
       "      <td>-2.127744</td>\n",
       "      <td>0.796369</td>\n",
       "      <td>-0.716186</td>\n",
       "      <td>1.027768</td>\n",
       "      <td>0.195807</td>\n",
       "      <td>0.248110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.189723</td>\n",
       "      <td>0.237422</td>\n",
       "      <td>0.331121</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>-0.070736</td>\n",
       "      <td>-1.098913</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>0.402748</td>\n",
       "      <td>-1.399115</td>\n",
       "      <td>1.195391</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>1.349864</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>-1.404673</td>\n",
       "      <td>-1.234635</td>\n",
       "      <td>0.082654</td>\n",
       "      <td>0.262612</td>\n",
       "      <td>0.252375</td>\n",
       "      <td>0.628164</td>\n",
       "      <td>-0.546476</td>\n",
       "      <td>-1.726632</td>\n",
       "      <td>0.207898</td>\n",
       "      <td>-0.615753</td>\n",
       "      <td>-0.282572</td>\n",
       "      <td>-1.944885</td>\n",
       "      <td>1.502839</td>\n",
       "      <td>1.140679</td>\n",
       "      <td>1.049812</td>\n",
       "      <td>0.174686</td>\n",
       "      <td>-0.182636</td>\n",
       "      <td>-0.234236</td>\n",
       "      <td>-1.121565</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>1.511350</td>\n",
       "      <td>-1.083609</td>\n",
       "      <td>1.251005</td>\n",
       "      <td>0.184234</td>\n",
       "      <td>2.330879</td>\n",
       "      <td>-1.164736</td>\n",
       "      <td>0.563984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.409833</td>\n",
       "      <td>-1.277760</td>\n",
       "      <td>-1.805131</td>\n",
       "      <td>-2.438984</td>\n",
       "      <td>-2.283404</td>\n",
       "      <td>-1.098913</td>\n",
       "      <td>-0.594366</td>\n",
       "      <td>-1.635103</td>\n",
       "      <td>-2.503236</td>\n",
       "      <td>-0.551132</td>\n",
       "      <td>-1.825205</td>\n",
       "      <td>0.324179</td>\n",
       "      <td>1.135141</td>\n",
       "      <td>0.374144</td>\n",
       "      <td>0.391036</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.669379</td>\n",
       "      <td>0.724304</td>\n",
       "      <td>2.320415</td>\n",
       "      <td>3.031447</td>\n",
       "      <td>0.212041</td>\n",
       "      <td>-0.172973</td>\n",
       "      <td>1.393984</td>\n",
       "      <td>0.816710</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>0.599779</td>\n",
       "      <td>-1.250570</td>\n",
       "      <td>-1.165914</td>\n",
       "      <td>-1.734574</td>\n",
       "      <td>-2.249622</td>\n",
       "      <td>-2.137725</td>\n",
       "      <td>-2.214074</td>\n",
       "      <td>-2.410660</td>\n",
       "      <td>-1.311923</td>\n",
       "      <td>-1.556391</td>\n",
       "      <td>-1.347863</td>\n",
       "      <td>-1.777268</td>\n",
       "      <td>-0.207225</td>\n",
       "      <td>-1.333801</td>\n",
       "      <td>0.099076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Asos      Amov      APOM      ASAG      AMOR  Awins_top25  \\\n",
       "124 -1.664805 -1.761074 -2.893411 -3.003016 -2.224661    -1.098913   \n",
       "101  0.638782  0.768515  0.472194  0.401318  0.438373     0.158626   \n",
       "184  1.211482  1.066883  0.653574  0.643046  0.692928     0.158626   \n",
       "134 -1.042908 -1.017338 -0.434705 -0.263433 -0.305710    -0.260554   \n",
       "78  -0.594948 -0.433107  0.109434  0.119303  0.242562     0.158626   \n",
       "52  -2.060314 -1.994766 -3.578624 -3.224600 -3.379948    -1.098913   \n",
       "10   0.744107  0.412869  0.673727  0.622902  0.614604     0.577805   \n",
       "105  0.189723  0.237422  0.331121  0.018583 -0.070736    -1.098913   \n",
       "104  0.189723  0.237422  0.331121  0.018583 -0.070736    -1.098913   \n",
       "8   -1.409833 -1.277760 -1.805131 -2.438984 -2.283404    -1.098913   \n",
       "\n",
       "     Awins_top5  Awin_pct    AAdjDE    AAdjOE    AAdjEM   AAdjsos     ALuck  \\\n",
       "124   -0.594366 -0.752348 -2.117587 -1.685875 -2.360871 -1.326659  3.098915   \n",
       "101    1.055815  0.340995 -0.099016  0.477517  0.262148  0.537661 -0.249725   \n",
       "184   -0.594366  0.584699  1.746456 -0.039163  0.989735 -0.384109 -0.301651   \n",
       "134   -0.594366 -0.652568 -0.789388 -0.552179 -0.828998 -0.809681  0.012789   \n",
       "78    -0.594366 -1.071642 -1.053316  0.483624 -0.288870  0.013816 -1.003087   \n",
       "52    -0.594366 -1.271201 -1.576473 -2.652265 -2.693156 -1.897097  3.410371   \n",
       "10     1.055815 -0.652568  1.553631  0.110903  0.978132 -0.948180 -1.320760   \n",
       "105   -0.594366  0.402748 -1.399115  1.195391 -0.013402  1.349864 -0.022535   \n",
       "104   -0.594366  0.402748 -1.399115  1.195391 -0.013402  1.349864 -0.022535   \n",
       "8     -0.594366 -1.635103 -2.503236 -0.551132 -1.825205  0.324179  1.135141   \n",
       "\n",
       "         Bsos      Bmov      BPOM      BSAG      BMOR  Bwins_top25  \\\n",
       "124  1.462180  1.129679  0.819705  0.785599  0.818690     1.051227   \n",
       "101  0.284002  0.233007  0.645141  0.611270  0.667672     0.628164   \n",
       "184  0.785278  1.055584  0.354200  0.320722  0.384515    -1.064086   \n",
       "134 -1.344465 -1.409769 -0.596208 -0.357224 -0.521589    -1.064086   \n",
       "78   1.711595  1.847849  0.683933  0.630640  0.629918    -0.641023   \n",
       "52   0.112233  0.080894 -2.109102 -2.642869 -3.126639    -1.064086   \n",
       "10   0.574329  0.588910  0.664537  0.630640  0.573287    -0.641023   \n",
       "105  1.793258  1.834774  0.761517  0.688749  0.686550     0.205102   \n",
       "104 -1.404673 -1.234635  0.082654  0.262612  0.252375     0.628164   \n",
       "8    0.374144  0.391036  0.606349  0.669379  0.724304     2.320415   \n",
       "\n",
       "     Bwins_top5  Bwin_pct    BAdjDE    BAdjOE    BAdjEM   BAdjsos     BLuck  \\\n",
       "124    1.242486  1.876212  2.038038  0.622339  1.622996 -0.296524 -0.608768   \n",
       "101    1.242486  0.436840  0.438999  0.513686  0.600095 -0.394365  0.353885   \n",
       "184   -0.546476  1.575975  0.062119  0.359011  0.273838  0.719422 -0.700520   \n",
       "134   -0.546476 -1.126158 -1.160098 -0.544817 -1.049577 -0.906992 -0.039497   \n",
       "78    -0.546476  1.311060 -0.017563  1.192595  0.776362  1.374932 -0.286472   \n",
       "52    -0.546476 -0.165400 -1.311863 -1.753497 -1.937224 -0.232148 -2.657369   \n",
       "10     1.242486 -0.000269  1.062118  0.505208  0.965138 -0.183720  0.803607   \n",
       "105   -0.546476  1.311060  1.696000  0.038761  1.034478 -0.112957 -0.227225   \n",
       "104   -0.546476 -1.726632  0.207898 -0.615753 -0.282572 -1.944885  1.502839   \n",
       "8      3.031447  0.212041 -0.172973  1.393984  0.816710  0.611182  0.599779   \n",
       "\n",
       "     sos_diff  mov_diff  POM_diff  SAG_diff  MOR_diff  wins_top25_diff  \\\n",
       "124 -2.209353 -2.030496 -2.667672 -2.741074 -2.165312        -1.394692   \n",
       "101  0.240998  0.365533 -0.141132 -0.168181 -0.179063        -0.302183   \n",
       "184  0.279968 -0.017501  0.203396  0.222089  0.207153         0.790326   \n",
       "134  0.238932  0.305798  0.131620  0.077544  0.165772         0.517198   \n",
       "78  -1.643282 -1.625121 -0.428239 -0.384998 -0.289410         0.517198   \n",
       "52  -1.515576 -1.440441 -0.988097 -0.341635 -0.096302        -0.029056   \n",
       "10   0.105903 -0.136135 -0.011934 -0.023637  0.014045         0.790326   \n",
       "105 -1.155398 -1.151047 -0.327751 -0.500634 -0.551484        -0.848438   \n",
       "104  1.140679  1.049812  0.174686 -0.182636 -0.234236        -1.121565   \n",
       "8   -1.250570 -1.165914 -1.734574 -2.249622 -2.137725        -2.214074   \n",
       "\n",
       "     wins_top5_diff  win_pct_diff  AdjDE_diff  AdjOE_diff  AdjEM_diff  \\\n",
       "124       -1.237425     -1.865825   -2.849282   -1.593388   -2.686226   \n",
       "101       -0.064189     -0.067778   -0.374389   -0.027938   -0.235195   \n",
       "184       -0.064189     -0.703032    1.126951   -0.276348    0.473754   \n",
       "134       -0.064189      0.335620    0.284912   -0.001859    0.163935   \n",
       "78        -0.064189     -1.691579   -0.693647   -0.495314   -0.723685   \n",
       "52        -0.064189     -0.785592   -0.136134   -0.608667   -0.474139   \n",
       "10        -0.064189     -0.463343    0.296059   -0.274545   -0.006612   \n",
       "105       -0.064189     -0.644285   -2.127744    0.796369   -0.716186   \n",
       "104       -0.064189      1.511350   -1.083609    1.251005    0.184234   \n",
       "8         -2.410660     -1.311923   -1.556391   -1.347863   -1.777268   \n",
       "\n",
       "     Adjsos_diff  Luck_diff  y_pred_confidence  y_pred_test  y_act  \n",
       "124    -0.720204  -1.874851           0.087474          0.0      1  \n",
       "101     0.657889  -0.088636           0.676542          1.0      0  \n",
       "184    -0.781340   0.779998           0.714511          1.0      1  \n",
       "134     0.076890   0.021348           0.632692          1.0      1  \n",
       "78     -0.968338   0.987119           0.254391          0.0      1  \n",
       "52     -1.166365  -0.500353           0.862022          1.0      1  \n",
       "10     -0.534805   0.371136           0.596478          1.0      0  \n",
       "105     1.027768   0.195807           0.248110          0.0      1  \n",
       "104     2.330879  -1.164736           0.563984          1.0      1  \n",
       "8      -0.207225  -1.333801           0.099076          0.0      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogLoss FN for accuracy weighted by confidence\n",
    "\n",
    "\n",
    "#Accuracy on Test set\n",
    "years=[2017,2018,2019]\n",
    "for year in years:\n",
    "    test_input_temp=test_input_data[test_input_data['Season']==year].reset_index(drop=True)\n",
    "    test_output_temp=test_output_data[test_output_data['Season']==year].reset_index(drop=True)\n",
    "    test_output_temp=test_output_temp[['AWon']]\n",
    "    \n",
    "    scores = model.evaluate(test_input_temp.iloc[:,0:inputs], test_output_temp, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    #Test LogLoss on holdout test set\n",
    "    y_pred_keras = model.predict(test_input_temp.iloc[:,0:inputs]).ravel()\n",
    "    y_pred_round=np.round(y_pred_keras,0)\n",
    "    temp = np.array(y_pred_keras)[np.newaxis]\n",
    "    np.set_printoptions(suppress=True)\n",
    "    y_pred_tran=temp.T\n",
    "    print(\"LL_Test \",year,\": \",LogLoss(y_pred_tran, test_output_temp))\n",
    "\n",
    "\n",
    "y_pred_keras = model.predict(test_input_data.iloc[:,0:inputs]).ravel()\n",
    "y_pred_round=np.round(y_pred_keras,0)\n",
    "testPerf=test_input_data.iloc[:,0:inputs]\n",
    "testPerf['y_pred_confidence']=y_pred_keras\n",
    "\n",
    "testPerf['y_pred_test']=y_pred_round\n",
    "testPerf['y_act']=test_output_data.AWon\n",
    "testPerf.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So that's cool, but how do we do at ACTUALLY picking a bracket?\n",
    "#### We start with the 2017 bracket and show each rounds matchups as my model picked them, followed by the calculated ESPN score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ATeamID               ATeam  BTeamID              BTeam\n",
      "0      1291      mount-st-marys     1437          villanova\n",
      "1      1458           wisconsin     1439      virginia-tech\n",
      "2      1438            virginia     1423     unc-wilmington\n",
      "3      1190   east-tennessee-st     1196            florida\n",
      "4      1425                 usc     1374                smu\n",
      "5      1308       new-mexico-st     1124             baylor\n",
      "6      1266           marquette     1376     south-carolina\n",
      "7      1407                troy     1181               duke\n",
      "8      1355     south-dakota-st     1211            gonzaga\n",
      "9      1321        northwestern     1435         vanderbilt\n",
      "10     1343           princeton     1323         notre-dame\n",
      "11     1137            bucknell     1452      west-virginia\n",
      "12     1268            maryland     1462             xavier\n",
      "13     1195  florida-gulf-coast     1199         florida-st\n",
      "14     1388         saint-marys     1433                vcu\n",
      "15     1315        north-dakota     1112            arizona\n",
      "16     1413            uc-davis     1242             kansas\n",
      "17     1277         michigan-st     1274           miami-fl\n",
      "18     1235             iowa-st     1305             nevada\n",
      "19     1436             vermont     1345             purdue\n",
      "20     1166           creighton     1348       rhode-island\n",
      "21     1332              oregon     1233               iona\n",
      "22     1329         oklahoma-st     1276           michigan\n",
      "23     1257          louisville     1240    jacksonville-st\n",
      "24     1314      north-carolina     1411     texas-southern\n",
      "25     1371          seton-hall     1116           arkansas\n",
      "26     1292    middle-tennessee     1278          minnesota\n",
      "27     1457            winthrop     1139             butler\n",
      "28     1243           kansas-st     1153         cincinnati\n",
      "29     1417                ucla     1245            kent-st\n",
      "30     1173              dayton     1455         wichita-st\n",
      "31     1246            kentucky     1297  northern-kentucky\n",
      "\n",
      "     ATeamID             ATeam  BTeamID          BTeam\n",
      "0    1437.0         villanova     1458      wisconsin\n",
      "1    1438.0          virginia     1196        florida\n",
      "2    1374.0               smu     1124         baylor\n",
      "3    1266.0         marquette     1181           duke\n",
      "4    1211.0           gonzaga     1321   northwestern\n",
      "5    1323.0        notre-dame     1452  west-virginia\n",
      "6    1268.0          maryland     1199     florida-st\n",
      "7    1388.0       saint-marys     1112        arizona\n",
      "8    1242.0            kansas     1277    michigan-st\n",
      "9    1235.0           iowa-st     1345         purdue\n",
      "10   1166.0         creighton     1332         oregon\n",
      "11   1329.0       oklahoma-st     1257     louisville\n",
      "12   1314.0    north-carolina     1371     seton-hall\n",
      "13   1292.0  middle-tennessee     1139         butler\n",
      "14   1153.0        cincinnati     1417           ucla\n",
      "15   1455.0        wichita-st     1246       kentucky\n",
      "\n",
      "    ATeamID           ATeam  BTeamID        BTeam\n",
      "0   1437.0       villanova   1438.0     virginia\n",
      "1   1374.0             smu   1181.0         duke\n",
      "2   1211.0         gonzaga   1323.0   notre-dame\n",
      "3   1199.0      florida-st   1388.0  saint-marys\n",
      "4   1242.0          kansas   1235.0      iowa-st\n",
      "5   1166.0       creighton   1257.0   louisville\n",
      "6   1314.0  north-carolina   1139.0       butler\n",
      "7   1153.0      cincinnati   1455.0   wichita-st\n",
      "\n",
      "    ATeamID           ATeam  BTeamID       BTeam\n",
      "0   1437.0       villanova   1374.0         smu\n",
      "1   1211.0         gonzaga   1199.0  florida-st\n",
      "2   1242.0          kansas   1257.0  louisville\n",
      "3   1314.0  north-carolina   1153.0  cincinnati\n",
      "\n",
      "    ATeamID      ATeam  BTeamID           BTeam\n",
      "0   1437.0  villanova   1211.0         gonzaga\n",
      "1   1242.0     kansas   1314.0  north-carolina\n",
      "\n",
      "    ATeamID    ATeam  BTeamID   BTeam\n",
      "0   1211.0  gonzaga   1242.0  kansas\n",
      "\n",
      "    ATeamID    ATeam\n",
      "0   1211.0  gonzaga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  score\n",
       "0     32     26\n",
       "1     16      8\n",
       "2      8     12\n",
       "3      4     16\n",
       "4      2     16\n",
       "5      1      0\n",
       "6  Total     78"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from runTournamentNew import runTournament\n",
    "\n",
    "df=pd.read_csv(\"../Data/TourneyData/tourney_game_master_scaled_all.csv\")\n",
    "#2017 results\n",
    "dfList, scoreDF=runTournament(df,2017,'../winModeling/tournament_win_model_prod','../winModeling/tournament_win_weights_prod',True)\n",
    "for df in dfList:\n",
    "    print('\\n',df)\n",
    "\n",
    "scoreDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017 could have been better, how about 2018?\n",
    "#### Same process as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ATeamID              ATeam  BTeamID                  BTeam\n",
      "0      1437          villanova     1347                radford\n",
      "1      1439      virginia-tech     1104                alabama\n",
      "2      1293          murray-st     1452          west-virginia\n",
      "3      1267           marshall     1455             wichita-st\n",
      "4      1382     st-bonaventure     1196                florida\n",
      "5      1403         texas-tech     1372       stephen-f-austin\n",
      "6      1116           arkansas     1139                 butler\n",
      "7      1168   cal-st-fullerton     1345                 purdue\n",
      "8      1335               penn     1242                 kansas\n",
      "9      1301  north-carolina-st     1371             seton-hall\n",
      "10     1308      new-mexico-st     1155                clemson\n",
      "11     1120             auburn     1158  college-of-charleston\n",
      "12     1395                tcu     1393               syracuse\n",
      "13     1137           bucknell     1277            michigan-st\n",
      "14     1328           oklahoma     1348           rhode-island\n",
      "15     1233               iona     1181                   duke\n",
      "16     1420               umbc     1438               virginia\n",
      "17     1243          kansas-st     1166              creighton\n",
      "18     1172           davidson     1246               kentucky\n",
      "19     1138            buffalo     1112                arizona\n",
      "20     1260     loyola-chicago     1274               miami-fl\n",
      "21     1460          wright-st     1397              tennessee\n",
      "22     1305             nevada     1400                  texas\n",
      "23     1209         georgia-st     1153             cincinnati\n",
      "24     1462             xavier     1411         texas-southern\n",
      "25     1199         florida-st     1281               missouri\n",
      "26     1355    south-dakota-st     1326                ohio-st\n",
      "27     1422     unc-greensboro     1211                gonzaga\n",
      "28     1222            houston     1361           san-diego-st\n",
      "29     1285            montana     1276               michigan\n",
      "30     1401           texas-am     1344             providence\n",
      "31     1252           lipscomb     1314         north-carolina\n",
      "\n",
      "     ATeamID           ATeam  BTeamID              BTeam\n",
      "0    1437.0       villanova     1439      virginia-tech\n",
      "1    1293.0       murray-st     1455         wichita-st\n",
      "2    1382.0  st-bonaventure     1403         texas-tech\n",
      "3    1116.0        arkansas     1345             purdue\n",
      "4    1242.0          kansas     1301  north-carolina-st\n",
      "5    1155.0         clemson     1120             auburn\n",
      "6    1395.0             tcu     1277        michigan-st\n",
      "7    1328.0        oklahoma     1181               duke\n",
      "8    1438.0        virginia     1243          kansas-st\n",
      "9    1246.0        kentucky     1112            arizona\n",
      "10   1260.0  loyola-chicago     1397          tennessee\n",
      "11   1305.0          nevada     1153         cincinnati\n",
      "12   1462.0          xavier     1199         florida-st\n",
      "13   1326.0         ohio-st     1211            gonzaga\n",
      "14   1222.0         houston     1276           michigan\n",
      "15   1401.0        texas-am     1314     north-carolina\n",
      "\n",
      "    ATeamID        ATeam  BTeamID           BTeam\n",
      "0   1437.0    villanova   1293.0       murray-st\n",
      "1   1403.0   texas-tech   1345.0          purdue\n",
      "2   1242.0       kansas   1155.0         clemson\n",
      "3   1277.0  michigan-st   1181.0            duke\n",
      "4   1438.0     virginia   1246.0        kentucky\n",
      "5   1397.0    tennessee   1153.0      cincinnati\n",
      "6   1462.0       xavier   1326.0         ohio-st\n",
      "7   1222.0      houston   1314.0  north-carolina\n",
      "\n",
      "    ATeamID      ATeam  BTeamID        BTeam\n",
      "0   1437.0  villanova   1345.0       purdue\n",
      "1   1242.0     kansas   1277.0  michigan-st\n",
      "2   1438.0   virginia   1397.0    tennessee\n",
      "3   1462.0     xavier   1222.0      houston\n",
      "\n",
      "    ATeamID      ATeam  BTeamID   BTeam\n",
      "0   1437.0  villanova   1242.0  kansas\n",
      "1   1438.0   virginia   1462.0  xavier\n",
      "\n",
      "    ATeamID      ATeam  BTeamID     BTeam\n",
      "0   1437.0  villanova   1438.0  virginia\n",
      "\n",
      "    ATeamID      ATeam\n",
      "0   1437.0  villanova\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  score\n",
       "0     32     22\n",
       "1     16     14\n",
       "2      8      8\n",
       "3      4     16\n",
       "4      2     16\n",
       "5      1     32\n",
       "6  Total    108"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2018 results\n",
    "df=pd.read_csv(\"../Data/TourneyData/tourney_game_master_scaled_all.csv\")\n",
    "#2017 results\n",
    "dfList, scoreDF=runTournament(df,2018,'../winModeling/tournament_win_model_prod','../winModeling/tournament_win_weights_prod',True)\n",
    "for df in dfList:\n",
    "    print('\\n',df)\n",
    "\n",
    "scoreDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We did ok considering a 16 seed upset a 1 seed in the 1st round 2018. Finally, this last year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     ATeamID              ATeam  BTeamID                BTeam\n",
      "0      1181               duke     1295      north-dakota-st\n",
      "1      1433                vcu     1416                  ucf\n",
      "2      1280     mississippi-st     1251              liberty\n",
      "3      1387        saint-louis     1439        virginia-tech\n",
      "4      1125            belmont     1268             maryland\n",
      "5      1261                lsu     1463                 yale\n",
      "6      1257         louisville     1278            minnesota\n",
      "7      1133            bradley     1277          michigan-st\n",
      "8      1211            gonzaga     1192  fairleigh-dickinson\n",
      "9      1124             baylor     1393             syracuse\n",
      "10     1293          murray-st     1266            marquette\n",
      "11     1199         florida-st     1436              vermont\n",
      "12     1138            buffalo     1113           arizona-st\n",
      "13     1297  northern-kentucky     1403           texas-tech\n",
      "14     1305             nevada     1196              florida\n",
      "15     1285            montana     1276             michigan\n",
      "16     1233               iona     1314       north-carolina\n",
      "17     1449         washington     1429              utah-st\n",
      "18     1120             auburn     1308        new-mexico-st\n",
      "19     1242             kansas     1318         northeastern\n",
      "20     1326            ohio-st     1235              iowa-st\n",
      "21     1209         georgia-st     1222              houston\n",
      "22     1459            wofford     1371           seton-hall\n",
      "23     1246           kentucky     1101    abilene-christian\n",
      "24     1205       gardner-webb     1438             virginia\n",
      "25     1279        mississippi     1328             oklahoma\n",
      "26     1332             oregon     1458            wisconsin\n",
      "27     1414          uc-irvine     1243            kansas-st\n",
      "28     1437          villanova     1388          saint-marys\n",
      "29     1345             purdue     1330         old-dominion\n",
      "30     1153         cincinnati     1234                 iowa\n",
      "31     1159            colgate     1397            tennessee\n",
      "\n",
      "     ATeamID           ATeam  BTeamID          BTeam\n",
      "0    1181.0            duke     1433            vcu\n",
      "1    1280.0  mississippi-st     1439  virginia-tech\n",
      "2    1268.0        maryland     1261            lsu\n",
      "3    1257.0      louisville     1277    michigan-st\n",
      "4    1211.0         gonzaga     1124         baylor\n",
      "5    1293.0       murray-st     1199     florida-st\n",
      "6    1138.0         buffalo     1403     texas-tech\n",
      "7    1305.0          nevada     1276       michigan\n",
      "8    1314.0  north-carolina     1449     washington\n",
      "9    1120.0          auburn     1242         kansas\n",
      "10   1235.0         iowa-st     1222        houston\n",
      "11   1459.0         wofford     1246       kentucky\n",
      "12   1438.0        virginia     1279    mississippi\n",
      "13   1458.0       wisconsin     1243      kansas-st\n",
      "14   1437.0       villanova     1345         purdue\n",
      "15   1153.0      cincinnati     1397      tennessee\n",
      "\n",
      "    ATeamID           ATeam  BTeamID           BTeam\n",
      "0   1181.0            duke   1280.0  mississippi-st\n",
      "1   1268.0        maryland   1277.0     michigan-st\n",
      "2   1211.0         gonzaga   1199.0      florida-st\n",
      "3   1403.0      texas-tech   1276.0        michigan\n",
      "4   1314.0  north-carolina   1120.0          auburn\n",
      "5   1235.0         iowa-st   1246.0        kentucky\n",
      "6   1438.0        virginia   1458.0       wisconsin\n",
      "7   1345.0          purdue   1397.0       tennessee\n",
      "\n",
      "    ATeamID           ATeam  BTeamID        BTeam\n",
      "0   1181.0            duke   1277.0  michigan-st\n",
      "1   1211.0         gonzaga   1276.0     michigan\n",
      "2   1314.0  north-carolina   1246.0     kentucky\n",
      "3   1438.0        virginia   1397.0    tennessee\n",
      "\n",
      "    ATeamID           ATeam  BTeamID     BTeam\n",
      "0   1277.0     michigan-st   1211.0   gonzaga\n",
      "1   1314.0  north-carolina   1438.0  virginia\n",
      "\n",
      "    ATeamID     ATeam  BTeamID        BTeam\n",
      "0   1438.0  virginia   1277.0  michigan-st\n",
      "\n",
      "    ATeamID     ATeam\n",
      "0   1438.0  virginia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round  score\n",
       "0     32     23\n",
       "1     16     24\n",
       "2      8     20\n",
       "3      4     16\n",
       "4      2     16\n",
       "5      1     32\n",
       "6  Total    131"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2019 results\n",
    "df=pd.read_csv(\"../Data/TourneyData/tourney_game_master_scaled_all.csv\")\n",
    "#2017 results\n",
    "dfList, scoreDF=runTournament(df,2019,'../winModeling/tournament_win_model_prod','../winModeling/tournament_win_weights_prod',True)\n",
    "for df in dfList:\n",
    "    print('\\n',df)\n",
    "\n",
    "scoreDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 went pretty well, but how well?\n",
    "#### Below is my models score compared to the average ESPN score and the score given that you just pick higher seeds\n",
    "#### Also shown is a percentile score compared to all other users on ESPN\n",
    "#### Here's a link to the 2019 leaderboard: http://fantasy.espn.com/tournament-challenge-bracket/2019/en/group?groupID=1041234\n",
    "#### Another note Nate Silver's Fivethirtyeight would only get 72 in 2017, 114 in 2018, and 95 in 2019: https://projects.fivethirtyeight.com/2018-march-madness-predictions/\n",
    "#### So not only is the model superior on statistical metrics, but it is good at the element humans care about - winning your office pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>higherSeed_score</th>\n",
       "      <th>myScore</th>\n",
       "      <th>percentile_myScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>65.7</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>57.0</td>\n",
       "      <td>81</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>74.0</td>\n",
       "      <td>124</td>\n",
       "      <td>131</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  avg_score  higherSeed_score  myScore  percentile_myScore\n",
       "0  2017       65.7                82       78                  68\n",
       "1  2018       57.0                81      108                  95\n",
       "2  2019       74.0               124      131                  99"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pastMadness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, are bigger companies with lots of staff doing better?\n",
    "#### Not quite, as far as I could find the only company publishing any kind of results is Adobe\n",
    "#### Their model achieves performance of a reported 98%, but this was just one year. Looking at on year we achieve 99%\n",
    "#### See this page: https://www.adobe.com/analytics/hack-the-bracket.html?red=a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, but how does this make anyone money, how about betting the spread?\n",
    "#### Well, beyond just raising your likelihood to win your office pool, I've also modified the model to predict against the spread\n",
    "#### So lets load some spread data and the model that predicts against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tourney_data=pd.read_csv(\"../Data/TourneyData/tourney_game_master_scaled_all.csv\")\n",
    "removeList=['Ats_pct','Aie','Afour','Aelo','Bts_pct','Bie','Bfour','Belo','ts_pct_diff','ie_diff','four_diff','elo_diff']\n",
    "if any(elem in tourney_data.columns  for elem in removeList):\n",
    "    tourney_data=tourney_data.drop(removeList,axis=1)\n",
    "tourney_data.dropna(subset=['AdjEM_diff'], how='all',inplace=True)\n",
    "tourney_data.dropna(subset=['line'], how='all',inplace=True)\n",
    "train_data=tourney_data[(tourney_data['Season']<2016)&(tourney_data['Season']>2003)].reset_index(drop=True)\n",
    "test_data=tourney_data[tourney_data['Season']>2015].reset_index(drop=True)\n",
    "\n",
    "#train_output_data=pd.DataFrame()\n",
    "#test_output_data=pd.DataFrame()\n",
    "col_names = ['Season','tourn_round','point_diff','ATeamID','ATeam','ASeed','Aregion','BTeamID','BTeam','BSeed','Bregion']\n",
    "train_other_data=train_data.iloc[:,inputs:inputs+11]\n",
    "train_output_data['ASpread']=train_data.ASpread\n",
    "train_output_data['Season']=train_data.Season\n",
    "test_other_data=test_data.iloc[:,inputs:inputs+11]\n",
    "test_output_data['ASpread']=test_data.ASpread\n",
    "train_input_data=train_data.iloc[:,:inputs]\n",
    "test_input_data=test_data.iloc[:,:inputs]\n",
    "test_full_data=test_input_data.copy()\n",
    "test_full_data[col_names] = test_other_data.copy()\n",
    "test_full_data['ASpread']=test_output_data['ASpread'].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "json_file = open(\"../spreadModeling/tournament_spread_model_prod.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "optimizer = keras.optimizers.Adagrad(lr=.001,epsilon=0,decay=0)\n",
    "model.compile(optimizer= optimizer ,loss='binary_crossentropy',metrics=['acc'])\n",
    "model.load_weights('../spreadModeling/tournament_spread_weights_prod.h5')\n",
    "\n",
    "print(\"Loaded model weights from disk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we compare performance for spread?\n",
    "#### Well because we are trying to beat vegas in this instance an average performance would be 50/50 because of how they try to set the lines\n",
    "#### With that being said a good log loss would be anything less that .69 and a good accuracy would obviously be better than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 67.69%\n",
      "LL_Test  2016 :  ASpread    0.65695\n",
      "dtype: float64\n",
      "acc: 52.24%\n",
      "LL_Test  2017 :  ASpread    0.701815\n",
      "dtype: float64\n",
      "acc: 64.18%\n",
      "LL_Test  2018 :  ASpread    0.668318\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asos</th>\n",
       "      <th>Amov</th>\n",
       "      <th>APOM</th>\n",
       "      <th>ASAG</th>\n",
       "      <th>AMOR</th>\n",
       "      <th>Awins_top25</th>\n",
       "      <th>Awins_top5</th>\n",
       "      <th>Awin_pct</th>\n",
       "      <th>AAdjDE</th>\n",
       "      <th>AAdjOE</th>\n",
       "      <th>AAdjEM</th>\n",
       "      <th>AAdjsos</th>\n",
       "      <th>ALuck</th>\n",
       "      <th>Bsos</th>\n",
       "      <th>Bmov</th>\n",
       "      <th>BPOM</th>\n",
       "      <th>BSAG</th>\n",
       "      <th>BMOR</th>\n",
       "      <th>Bwins_top25</th>\n",
       "      <th>Bwins_top5</th>\n",
       "      <th>Bwin_pct</th>\n",
       "      <th>BAdjDE</th>\n",
       "      <th>BAdjOE</th>\n",
       "      <th>BAdjEM</th>\n",
       "      <th>BAdjsos</th>\n",
       "      <th>BLuck</th>\n",
       "      <th>sos_diff</th>\n",
       "      <th>mov_diff</th>\n",
       "      <th>POM_diff</th>\n",
       "      <th>SAG_diff</th>\n",
       "      <th>MOR_diff</th>\n",
       "      <th>wins_top25_diff</th>\n",
       "      <th>wins_top5_diff</th>\n",
       "      <th>win_pct_diff</th>\n",
       "      <th>AdjDE_diff</th>\n",
       "      <th>AdjOE_diff</th>\n",
       "      <th>AdjEM_diff</th>\n",
       "      <th>Adjsos_diff</th>\n",
       "      <th>Luck_diff</th>\n",
       "      <th>y_pred_confidence</th>\n",
       "      <th>y_pred_test</th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.707631</td>\n",
       "      <td>-0.646100</td>\n",
       "      <td>-1.324682</td>\n",
       "      <td>-1.282199</td>\n",
       "      <td>-1.403553</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>-0.099096</td>\n",
       "      <td>-0.335889</td>\n",
       "      <td>-1.751944</td>\n",
       "      <td>-1.354867</td>\n",
       "      <td>-1.681564</td>\n",
       "      <td>1.584358</td>\n",
       "      <td>-0.051118</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>0.777556</td>\n",
       "      <td>0.672479</td>\n",
       "      <td>0.743592</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>1.410179</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>0.721236</td>\n",
       "      <td>0.574341</td>\n",
       "      <td>0.802957</td>\n",
       "      <td>-0.686781</td>\n",
       "      <td>0.643023</td>\n",
       "      <td>-0.453098</td>\n",
       "      <td>-0.427580</td>\n",
       "      <td>-1.789040</td>\n",
       "      <td>-1.667219</td>\n",
       "      <td>-1.801088</td>\n",
       "      <td>-1.092224</td>\n",
       "      <td>-1.144929</td>\n",
       "      <td>-0.323390</td>\n",
       "      <td>-0.754827</td>\n",
       "      <td>-1.634219</td>\n",
       "      <td>-1.496829</td>\n",
       "      <td>-0.692316</td>\n",
       "      <td>-1.994886</td>\n",
       "      <td>0.393901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.267872</td>\n",
       "      <td>-0.196477</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>0.470271</td>\n",
       "      <td>0.497736</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>1.410179</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>0.517069</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>0.302955</td>\n",
       "      <td>-0.470193</td>\n",
       "      <td>-0.389709</td>\n",
       "      <td>1.213858</td>\n",
       "      <td>1.146801</td>\n",
       "      <td>0.489346</td>\n",
       "      <td>0.588225</td>\n",
       "      <td>0.612469</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.536812</td>\n",
       "      <td>-0.129326</td>\n",
       "      <td>0.844792</td>\n",
       "      <td>0.482272</td>\n",
       "      <td>0.838593</td>\n",
       "      <td>0.342090</td>\n",
       "      <td>-1.005063</td>\n",
       "      <td>-0.899023</td>\n",
       "      <td>0.017748</td>\n",
       "      <td>-0.112616</td>\n",
       "      <td>-0.105482</td>\n",
       "      <td>1.094675</td>\n",
       "      <td>1.124575</td>\n",
       "      <td>-0.218331</td>\n",
       "      <td>0.476400</td>\n",
       "      <td>-0.595162</td>\n",
       "      <td>-0.120536</td>\n",
       "      <td>-0.906420</td>\n",
       "      <td>0.078987</td>\n",
       "      <td>0.469972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.461734</td>\n",
       "      <td>1.830803</td>\n",
       "      <td>0.879277</td>\n",
       "      <td>0.891537</td>\n",
       "      <td>0.858325</td>\n",
       "      <td>1.910155</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>1.294767</td>\n",
       "      <td>0.850198</td>\n",
       "      <td>1.322046</td>\n",
       "      <td>0.298531</td>\n",
       "      <td>-0.727749</td>\n",
       "      <td>3.327436</td>\n",
       "      <td>3.667013</td>\n",
       "      <td>0.947092</td>\n",
       "      <td>0.942089</td>\n",
       "      <td>0.923887</td>\n",
       "      <td>1.910155</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>2.454171</td>\n",
       "      <td>1.678007</td>\n",
       "      <td>1.566276</td>\n",
       "      <td>2.020196</td>\n",
       "      <td>2.078980</td>\n",
       "      <td>-0.561591</td>\n",
       "      <td>-1.261891</td>\n",
       "      <td>-1.224139</td>\n",
       "      <td>-0.068290</td>\n",
       "      <td>-0.055566</td>\n",
       "      <td>-0.064459</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>-1.475564</td>\n",
       "      <td>-0.267774</td>\n",
       "      <td>-0.504108</td>\n",
       "      <td>-0.481448</td>\n",
       "      <td>-1.228023</td>\n",
       "      <td>1.210930</td>\n",
       "      <td>0.422274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.408523</td>\n",
       "      <td>-1.505540</td>\n",
       "      <td>-2.155405</td>\n",
       "      <td>-2.225837</td>\n",
       "      <td>-1.567457</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>-0.519615</td>\n",
       "      <td>-1.675330</td>\n",
       "      <td>-1.359866</td>\n",
       "      <td>-1.882310</td>\n",
       "      <td>-1.167008</td>\n",
       "      <td>2.340631</td>\n",
       "      <td>1.860492</td>\n",
       "      <td>1.477702</td>\n",
       "      <td>0.947092</td>\n",
       "      <td>0.925239</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.410179</td>\n",
       "      <td>2.145852</td>\n",
       "      <td>2.301876</td>\n",
       "      <td>0.859658</td>\n",
       "      <td>1.919616</td>\n",
       "      <td>-0.116482</td>\n",
       "      <td>-0.366274</td>\n",
       "      <td>-2.200527</td>\n",
       "      <td>-1.980669</td>\n",
       "      <td>-2.635075</td>\n",
       "      <td>-2.679850</td>\n",
       "      <td>-2.115595</td>\n",
       "      <td>-1.365586</td>\n",
       "      <td>-1.144929</td>\n",
       "      <td>-1.870681</td>\n",
       "      <td>-2.865328</td>\n",
       "      <td>-1.559290</td>\n",
       "      <td>-2.640502</td>\n",
       "      <td>-0.730325</td>\n",
       "      <td>-1.764231</td>\n",
       "      <td>0.387791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.452925</td>\n",
       "      <td>-0.431148</td>\n",
       "      <td>-0.866937</td>\n",
       "      <td>-0.945186</td>\n",
       "      <td>-0.698765</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.388434</td>\n",
       "      <td>-1.532755</td>\n",
       "      <td>-0.316915</td>\n",
       "      <td>-1.109386</td>\n",
       "      <td>-0.137434</td>\n",
       "      <td>1.443671</td>\n",
       "      <td>0.451765</td>\n",
       "      <td>0.776550</td>\n",
       "      <td>0.641928</td>\n",
       "      <td>0.621927</td>\n",
       "      <td>0.694421</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>0.473156</td>\n",
       "      <td>0.895132</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>-0.053958</td>\n",
       "      <td>0.665980</td>\n",
       "      <td>-0.619097</td>\n",
       "      <td>-0.809601</td>\n",
       "      <td>-1.287154</td>\n",
       "      <td>-1.339183</td>\n",
       "      <td>-1.172073</td>\n",
       "      <td>-1.365586</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>-1.440567</td>\n",
       "      <td>-0.852199</td>\n",
       "      <td>-1.372188</td>\n",
       "      <td>-0.070942</td>\n",
       "      <td>-1.887564</td>\n",
       "      <td>0.396445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.685197</td>\n",
       "      <td>0.626303</td>\n",
       "      <td>0.760603</td>\n",
       "      <td>0.739881</td>\n",
       "      <td>0.809154</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>-0.012381</td>\n",
       "      <td>0.835828</td>\n",
       "      <td>0.437679</td>\n",
       "      <td>0.779941</td>\n",
       "      <td>-0.473394</td>\n",
       "      <td>-0.834920</td>\n",
       "      <td>0.181940</td>\n",
       "      <td>0.442430</td>\n",
       "      <td>-0.917797</td>\n",
       "      <td>-1.063140</td>\n",
       "      <td>-1.485505</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.727585</td>\n",
       "      <td>-0.558229</td>\n",
       "      <td>-1.090597</td>\n",
       "      <td>-1.048342</td>\n",
       "      <td>-0.393952</td>\n",
       "      <td>-1.555005</td>\n",
       "      <td>0.322639</td>\n",
       "      <td>0.108216</td>\n",
       "      <td>1.408687</td>\n",
       "      <td>1.513300</td>\n",
       "      <td>1.904632</td>\n",
       "      <td>1.368038</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>-0.558460</td>\n",
       "      <td>1.016775</td>\n",
       "      <td>1.071077</td>\n",
       "      <td>1.275995</td>\n",
       "      <td>-0.068191</td>\n",
       "      <td>2.214215</td>\n",
       "      <td>0.614584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.283823</td>\n",
       "      <td>0.354428</td>\n",
       "      <td>0.591067</td>\n",
       "      <td>0.689329</td>\n",
       "      <td>0.661640</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>3.308303</td>\n",
       "      <td>-0.320700</td>\n",
       "      <td>-0.617578</td>\n",
       "      <td>1.747872</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.925673</td>\n",
       "      <td>-1.039876</td>\n",
       "      <td>0.230359</td>\n",
       "      <td>0.297191</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.809154</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.912576</td>\n",
       "      <td>-0.068704</td>\n",
       "      <td>1.383667</td>\n",
       "      <td>0.873958</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>0.021786</td>\n",
       "      <td>0.024692</td>\n",
       "      <td>-0.197346</td>\n",
       "      <td>-0.027041</td>\n",
       "      <td>-0.132830</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>2.259327</td>\n",
       "      <td>-0.894649</td>\n",
       "      <td>-0.387487</td>\n",
       "      <td>0.254082</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>0.740318</td>\n",
       "      <td>0.457010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.230359</td>\n",
       "      <td>0.297191</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.809154</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.912576</td>\n",
       "      <td>-0.068704</td>\n",
       "      <td>1.383667</td>\n",
       "      <td>0.873958</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>-0.266788</td>\n",
       "      <td>-3.057738</td>\n",
       "      <td>-2.886611</td>\n",
       "      <td>-3.579502</td>\n",
       "      <td>-3.557039</td>\n",
       "      <td>-2.763957</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>-3.095571</td>\n",
       "      <td>-2.288972</td>\n",
       "      <td>-2.432903</td>\n",
       "      <td>-2.951553</td>\n",
       "      <td>-2.279589</td>\n",
       "      <td>-2.430834</td>\n",
       "      <td>2.185339</td>\n",
       "      <td>2.086832</td>\n",
       "      <td>3.703021</td>\n",
       "      <td>3.595612</td>\n",
       "      <td>2.971223</td>\n",
       "      <td>1.094675</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>2.677359</td>\n",
       "      <td>1.613923</td>\n",
       "      <td>2.677099</td>\n",
       "      <td>2.665311</td>\n",
       "      <td>2.323640</td>\n",
       "      <td>2.494709</td>\n",
       "      <td>0.622497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.241671</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.692789</td>\n",
       "      <td>0.402868</td>\n",
       "      <td>0.612469</td>\n",
       "      <td>0.047312</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.536812</td>\n",
       "      <td>-0.204796</td>\n",
       "      <td>1.141427</td>\n",
       "      <td>0.633986</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>-0.417781</td>\n",
       "      <td>-0.642923</td>\n",
       "      <td>-0.583980</td>\n",
       "      <td>-1.070379</td>\n",
       "      <td>-0.928335</td>\n",
       "      <td>-0.862669</td>\n",
       "      <td>-0.884110</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.465016</td>\n",
       "      <td>-1.647956</td>\n",
       "      <td>-0.262182</td>\n",
       "      <td>-1.140843</td>\n",
       "      <td>-0.237664</td>\n",
       "      <td>-1.550469</td>\n",
       "      <td>0.577705</td>\n",
       "      <td>0.709982</td>\n",
       "      <td>1.480385</td>\n",
       "      <td>1.113952</td>\n",
       "      <td>1.220920</td>\n",
       "      <td>0.547951</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>-0.005248</td>\n",
       "      <td>1.052265</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>1.238811</td>\n",
       "      <td>0.636195</td>\n",
       "      <td>1.829819</td>\n",
       "      <td>0.612728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.230359</td>\n",
       "      <td>0.297191</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.809154</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>-0.487945</td>\n",
       "      <td>0.912576</td>\n",
       "      <td>-0.068704</td>\n",
       "      <td>1.383667</td>\n",
       "      <td>0.873958</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>-0.266788</td>\n",
       "      <td>0.366732</td>\n",
       "      <td>0.490142</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.840985</td>\n",
       "      <td>0.759983</td>\n",
       "      <td>2.375866</td>\n",
       "      <td>1.410179</td>\n",
       "      <td>0.536812</td>\n",
       "      <td>0.769597</td>\n",
       "      <td>0.987535</td>\n",
       "      <td>1.104376</td>\n",
       "      <td>0.105080</td>\n",
       "      <td>0.575285</td>\n",
       "      <td>-0.105192</td>\n",
       "      <td>-0.140320</td>\n",
       "      <td>-0.025271</td>\n",
       "      <td>-0.126878</td>\n",
       "      <td>0.031261</td>\n",
       "      <td>-0.818861</td>\n",
       "      <td>-1.144929</td>\n",
       "      <td>0.201905</td>\n",
       "      <td>-0.596671</td>\n",
       "      <td>0.276490</td>\n",
       "      <td>-0.156082</td>\n",
       "      <td>0.697654</td>\n",
       "      <td>-0.245646</td>\n",
       "      <td>0.432726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Asos      Amov      APOM      ASAG      AMOR  Awins_top25  \\\n",
       "182 -0.707631 -0.646100 -1.324682 -1.282199 -1.403553    -0.884110   \n",
       "6   -0.267872 -0.196477  0.523253  0.470271  0.497736     0.978733   \n",
       "79   1.461734  1.830803  0.879277  0.891537  0.858325     1.910155   \n",
       "189 -1.408523 -1.505540 -2.155405 -2.225837 -1.567457    -0.884110   \n",
       "77  -0.452925 -0.431148 -0.866937 -0.945186 -0.698765    -0.884110   \n",
       "187  0.685197  0.626303  0.760603  0.739881  0.809154     1.444444   \n",
       "36   0.283823  0.354428  0.591067  0.689329  0.661640     0.978733   \n",
       "38   0.230359  0.297191  0.811463  0.706180  0.809154     0.978733   \n",
       "133  0.241671  0.512276  0.692789  0.402868  0.612469     0.047312   \n",
       "35   0.230359  0.297191  0.811463  0.706180  0.809154     0.978733   \n",
       "\n",
       "     Awins_top5  Awin_pct    AAdjDE    AAdjOE    AAdjEM   AAdjsos     ALuck  \\\n",
       "182   -0.487945 -0.099096 -0.335889 -1.751944 -1.354867 -1.681564  1.584358   \n",
       "6      1.410179  0.295938  0.517069 -0.001022  0.302955 -0.470193 -0.389709   \n",
       "79    -0.487945  0.368484  1.294767  0.850198  1.322046  0.298531 -0.727749   \n",
       "189   -0.487945 -0.519615 -1.675330 -1.359866 -1.882310 -1.167008  2.340631   \n",
       "77    -0.487945  0.388434 -1.532755 -0.316915 -1.109386 -0.137434  1.443671   \n",
       "187   -0.487945 -0.012381  0.835828  0.437679  0.779941 -0.473394 -0.834920   \n",
       "36     3.308303 -0.320700 -0.617578  1.747872  0.792308  0.925673 -1.039876   \n",
       "38    -0.487945  0.912576 -0.068704  1.383667  0.873958  1.148825 -0.266788   \n",
       "133   -0.487945  0.536812 -0.204796  1.141427  0.633986  0.715946 -0.417781   \n",
       "35    -0.487945  0.912576 -0.068704  1.383667  0.873958  1.148825 -0.266788   \n",
       "\n",
       "         Bsos      Bmov      BPOM      BSAG      BMOR  Bwins_top25  \\\n",
       "182 -0.051118 -0.017612  0.777556  0.672479  0.743592     0.978733   \n",
       "6    1.213858  1.146801  0.489346  0.588225  0.612469    -0.884110   \n",
       "79   3.327436  3.667013  0.947092  0.942089  0.923887     1.910155   \n",
       "189  1.860492  1.477702  0.947092  0.925239  0.956668     1.444444   \n",
       "77   0.451765  0.776550  0.641928  0.621927  0.694421     1.444444   \n",
       "187  0.181940  0.442430 -0.917797 -1.063140 -1.485505    -0.884110   \n",
       "36   0.230359  0.297191  0.811463  0.706180  0.809154     0.978733   \n",
       "38  -3.057738 -2.886611 -3.579502 -3.557039 -2.763957    -0.884110   \n",
       "133 -0.642923 -0.583980 -1.070379 -0.928335 -0.862669    -0.884110   \n",
       "35   0.366732  0.490142  0.828417  0.840985  0.759983     2.375866   \n",
       "\n",
       "     Bwins_top5  Bwin_pct    BAdjDE    BAdjOE    BAdjEM   BAdjsos     BLuck  \\\n",
       "182    1.410179  0.295938  0.721236  0.574341  0.802957 -0.686781  0.643023   \n",
       "6     -0.487945  0.536812 -0.129326  0.844792  0.482272  0.838593  0.342090   \n",
       "79    -0.487945  2.454171  1.678007  1.566276  2.020196  2.078980 -0.561591   \n",
       "189    1.410179  2.145852  2.301876  0.859658  1.919616 -0.116482 -0.366274   \n",
       "77    -0.487945  0.295938  0.473156  0.895132  0.869259 -0.053958  0.665980   \n",
       "187   -0.487945  0.727585 -0.558229 -1.090597 -1.048342 -0.393952 -1.555005   \n",
       "36    -0.487945  0.912576 -0.068704  1.383667  0.873958  1.148825  0.266788   \n",
       "38    -0.487945 -3.095571 -2.288972 -2.432903 -2.951553 -2.279589 -2.430834   \n",
       "133   -0.487945  0.465016 -1.647956 -0.262182 -1.140843 -0.237664 -1.550469   \n",
       "35     1.410179  0.536812  0.769597  0.987535  1.104376  0.105080  0.575285   \n",
       "\n",
       "     sos_diff  mov_diff  POM_diff  SAG_diff  MOR_diff  wins_top25_diff  \\\n",
       "182 -0.453098 -0.427580 -1.789040 -1.667219 -1.801088        -1.092224   \n",
       "6   -1.005063 -0.899023  0.017748 -0.112616 -0.105482         1.094675   \n",
       "79  -1.261891 -1.224139 -0.068290 -0.055566 -0.064459         0.001226   \n",
       "189 -2.200527 -1.980669 -2.635075 -2.679850 -2.115595        -1.365586   \n",
       "77  -0.619097 -0.809601 -1.287154 -1.339183 -1.172073        -1.365586   \n",
       "187  0.322639  0.108216  1.408687  1.513300  1.904632         1.368038   \n",
       "36   0.021786  0.024692 -0.197346 -0.027041 -0.132830         0.001226   \n",
       "38   2.185339  2.086832  3.703021  3.595612  2.971223         1.094675   \n",
       "133  0.577705  0.709982  1.480385  1.113952  1.220920         0.547951   \n",
       "35  -0.105192 -0.140320 -0.025271 -0.126878  0.031261        -0.818861   \n",
       "\n",
       "     wins_top5_diff  win_pct_diff  AdjDE_diff  AdjOE_diff  AdjEM_diff  \\\n",
       "182       -1.144929     -0.323390   -0.754827   -1.634219   -1.496829   \n",
       "6          1.124575     -0.218331    0.476400   -0.595162   -0.120536   \n",
       "79        -0.010177     -1.475564   -0.267774   -0.504108   -0.481448   \n",
       "189       -1.144929     -1.870681   -2.865328   -1.559290   -2.640502   \n",
       "77        -0.010177      0.008859   -1.440567   -0.852199   -1.372188   \n",
       "187       -0.010177     -0.558460    1.016775    1.071077    1.275995   \n",
       "36         2.259327     -0.894649   -0.387487    0.254082   -0.052596   \n",
       "38        -0.010177      2.677359    1.613923    2.677099    2.665311   \n",
       "133       -0.010177     -0.005248    1.052265    0.983580    1.238811   \n",
       "35        -1.144929      0.201905   -0.596671    0.276490   -0.156082   \n",
       "\n",
       "     Adjsos_diff  Luck_diff  y_pred_confidence  y_pred_test  y_act  \n",
       "182    -0.692316  -1.994886           0.393901          0.0      0  \n",
       "6      -0.906420   0.078987           0.469972          0.0      0  \n",
       "79     -1.228023   1.210930           0.422274          0.0      0  \n",
       "189    -0.730325  -1.764231           0.387791          0.0      0  \n",
       "77     -0.070942  -1.887564           0.396445          0.0      1  \n",
       "187    -0.068191   2.214215           0.614584          1.0      0  \n",
       "36     -0.166180   0.740318           0.457010          0.0      0  \n",
       "38      2.323640   2.494709           0.622497          1.0      1  \n",
       "133     0.636195   1.829819           0.612728          1.0      0  \n",
       "35      0.697654  -0.245646           0.432726          0.0      0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "years=[2016,2017,2018]\n",
    "for year in years:\n",
    "    test_input_temp=test_full_data[test_full_data['Season']==year].reset_index(drop=True)\n",
    "    test_output_temp=test_full_data[test_full_data['Season']==year].reset_index(drop=True)\n",
    "    test_output_temp=test_output_temp[['ASpread']]\n",
    "    \n",
    "    scores = model.evaluate(test_input_temp.iloc[:,0:inputs], test_output_temp, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    #Test LogLoss on holdout test set\n",
    "    y_pred_keras = model.predict(test_input_temp.iloc[:,0:inputs]).ravel()\n",
    "    y_pred_round=np.round(y_pred_keras,0)\n",
    "    temp = np.array(y_pred_keras)[np.newaxis]\n",
    "    np.set_printoptions(suppress=True)\n",
    "    y_pred_tran=temp.T\n",
    "    print(\"LL_Test \",year,\": \",LogLoss(y_pred_tran, test_output_temp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#show pred df for last season\n",
    "y_pred_keras = model.predict(test_input_data.iloc[:,0:inputs]).ravel()\n",
    "y_pred_round=np.round(y_pred_keras,0)\n",
    "testPerf=test_input_data.iloc[:,0:inputs]\n",
    "testPerf['y_pred_confidence']=y_pred_keras\n",
    "\n",
    "testPerf['y_pred_test']=y_pred_round\n",
    "testPerf['y_act']=test_output_data.ASpread\n",
    "\n",
    "testPerf.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This average of 61.4% accuracy tells us over the long run we could stand to make a bit of money in Vegas, we could maybe even eke out extra performance if we focused on picks our model was most confident in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
